{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRFTxAuJrrLyMtRLaZylqn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreihMurray/NLP-3/blob/Super_Murray/supervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "zwkkSetusdVb"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Reshape\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import load_model\n",
        "import joblib\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "import nltk\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjngr6X6sk7r",
        "outputId": "336f5799-0d6a-4b0b-cf81-cbd0d32137fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file_to_sents():\n",
        "    all_data = []\n",
        "    with open(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/train.tsv\", encoding=\"utf-8\") as file:\n",
        "        f = csv.reader(file, delimiter=\"\\t\")\n",
        "        for line in tqdm(f, desc=\"Reading data...\"):\n",
        "            word = line[0]\n",
        "            graphemes = line[1].split('-')\n",
        "\n",
        "            cur_word = []\n",
        "\n",
        "            for i in range(0, len(graphemes)):\n",
        "                if len(graphemes[i]) == 1:\n",
        "                    cur_word.append((word[i], 'B'))\n",
        "                else:\n",
        "                    cur_word.append((word[i], 'B'))\n",
        "                    for j in range(i+1, (i + len(graphemes[i]))):\n",
        "                        cur_word.append((word[j], 'I'))\n",
        "                        i += j\n",
        "\n",
        "            all_data.append(cur_word)\n",
        "\n",
        "    return all_data"
      ],
      "metadata": {
        "id": "pEpjh6qgsoYf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad(data):\n",
        "  vocab = list(set([w for sent in data for (w,t) in sent]))\n",
        "  vocab.append('<PAD>')\n",
        "  tags = list(set([t for sent in data for (w,t) in sent]))\n",
        "  tags.append('<PAD>')\n",
        "\n",
        "  return vocab, tags"
      ],
      "metadata": {
        "id": "SyCX8WWu4Wis"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(vocab, tags, data, load=False):\n",
        "  max_len = max([len(i) for i in data])\n",
        "\n",
        "  word2index = {}\n",
        "  tag2index = {}\n",
        "\n",
        "  if load is False:\n",
        "      word2index = {w: i for i, w in enumerate(vocab)}\n",
        "      tag2index = {t: i for i, t in enumerate(tags)}\n",
        "  else:\n",
        "      with open(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/word2index.json\") as infile:\n",
        "          word2index = json.load(infile)  \n",
        "\n",
        "      with open(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/tag2index.json\") as outfile:\n",
        "          tag2index = json.load(outfile)\n",
        "\n",
        "  print(type(word2index))\n",
        "  print(type(tag2index))\n",
        "\n",
        "  onehot = [[word2index[w[0]] for w in s] for s in data]\n",
        "  X = pad_sequences(maxlen=max_len, sequences=onehot, padding=\"post\", value=len(vocab)-1)  \n",
        "\n",
        "  onehot_y = [[tag2index[w[1]] for w in s] for s in data]\n",
        "  y = pad_sequences(maxlen=max_len, sequences=onehot_y, padding=\"post\", value=tag2index[\"<PAD>\"])\n",
        "  y = to_categorical(y, num_classes=len(tags))\n",
        "\n",
        "  # Used for saving word2index and tag2index in order to encode additional data in the same manner\n",
        "  # Currently commented out due to issues with loading model\n",
        "  with open(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/word2index.json\", \"w\") as outfile:\n",
        "    json.dump(word2index, outfile)\n",
        "\n",
        "  with open(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/tag2index.json\", \"w\") as outfile:\n",
        "    json.dump(tag2index, outfile)\n",
        "\n",
        "  return X, y, max_len"
      ],
      "metadata": {
        "id": "nzxivxza4ZKR"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seq_model(data):\n",
        "  #Original\n",
        "    vocab, tags = pad(data)\n",
        "\n",
        "    x, y, max_len = encode(vocab, tags, data)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
        "  \n",
        "  \n",
        "  # Dr. Scannell\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(vocab), output_dim=50, input_length=max_len))\n",
        "    model.add(Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.05)))\n",
        "    model.add(TimeDistributed(Dense(len(tags), activation=\"softmax\")))\n",
        "    model.compile(optimizer=\"adam\", loss=\"poisson\", metrics=[\"accuracy\"])\n",
        "  # From https://towardsdatascience.com/hyperparameter-tuning-with-kerastuner-and-tensorflow-c4a4d690b31a\n",
        "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)\n",
        "\n",
        "    print(\"[INFO] training network...\")\n",
        "    sgd = SGD(0.05)\n",
        "    history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_split=0.15, verbose=1, callbacks=stop_early)\n",
        "\n",
        "    return model, X_test, y_test"
      ],
      "metadata": {
        "id": "FVR17k8e4bxB"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_precision(preds, y_test):\n",
        "    true_pos = 0\n",
        "    false_pos = 0\n",
        "\n",
        "    for i in range(0, len(preds)):\n",
        "        if str(preds[i]) == 'B' and str(y_test[i]) == 'B':\n",
        "            true_pos += 1\n",
        "        if str(preds[i]) == 'B' and str(y_test[i]) == 'I':\n",
        "            false_pos += 1\n",
        "\n",
        "    if (true_pos + false_pos) == 0:\n",
        "        return 0.01\n",
        "\n",
        "    precision = 100 * (true_pos / (true_pos + false_pos))\n",
        "\n",
        "    return precision"
      ],
      "metadata": {
        "id": "Y9m8uO1d-_KH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_recall(preds, y_test):\n",
        "    true_pos = 0\n",
        "    false_neg = 0\n",
        "\n",
        "    for i in range(0, len(preds)):\n",
        "        if str(preds[i]) == 'B' and str(y_test[i]) == 'B':\n",
        "            true_pos += 1\n",
        "        if str(preds[i]) == 'I' and str(y_test[i]) == 'B':\n",
        "            false_neg += 1\n",
        "\n",
        "    if true_pos + false_neg == 0:\n",
        "        return 0\n",
        "        \n",
        "    recall = 100 * (true_pos / (true_pos + false_neg))\n",
        "\n",
        "    return recall"
      ],
      "metadata": {
        "id": "KYP5sEdp_eg7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, x_test, y_test):\n",
        "    eval = model.evaluate(x_test, y_test)\n",
        "    print(eval)"
      ],
      "metadata": {
        "id": "k_MUYsLr40jx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def supervised():\n",
        "    data = read_file_to_sents()\n",
        "\n",
        "    model, x_test, y_test = seq_model(data)\n",
        "\n",
        "    eval_model(model, x_test, y_test) # Eval sequential model\n",
        "\n",
        "    model.save('/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/adamPoisson32TEST_seq_model')\n",
        "\n",
        "    new_model = load_model('/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/adamPoisson32TEST_seq_model')\n",
        "\n",
        "    eval_model(new_model, x_test, y_test)"
      ],
      "metadata": {
        "id": "-NtZSkDetvsB"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_eval_model():\n",
        "    data = read_file_to_sents()\n",
        "\n",
        "    vocab, tags = pad(data)\n",
        "\n",
        "    x, y, max_len = encode(vocab, tags, data, load=True)\n",
        "\n",
        "    new_model = load_model('/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/adamPoisson32TEST_seq_model')\n",
        "\n",
        "    eval_model(new_model, x, y)"
      ],
      "metadata": {
        "id": "hvLR537CzpQg"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_and_eval_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJslV8Ryz3R2",
        "outputId": "d38bc6a3-7dda-4283-eee5-79d03032dece"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading data...: 12812it [00:01, 10478.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "<class 'dict'>\n",
            "401/401 [==============================] - 5s 12ms/step - loss: 0.3342 - accuracy: 0.9989\n",
            "[0.3342019021511078, 0.9989246129989624]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "supervised()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn5J86L8uH9u",
        "outputId": "119e229d-10bf-42d6-a380-f8060fe817b5"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading data...: 12812it [00:00, 176605.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training network...\n",
            "Epoch 1/50\n",
            "307/307 [==============================] - 28s 70ms/step - loss: 0.3855 - accuracy: 0.9480 - val_loss: 0.3495 - val_accuracy: 0.9857\n",
            "Epoch 2/50\n",
            "307/307 [==============================] - 22s 73ms/step - loss: 0.3446 - accuracy: 0.9882 - val_loss: 0.3414 - val_accuracy: 0.9904\n",
            "Epoch 3/50\n",
            "307/307 [==============================] - 22s 71ms/step - loss: 0.3386 - accuracy: 0.9941 - val_loss: 0.3374 - val_accuracy: 0.9952\n",
            "Epoch 4/50\n",
            "307/307 [==============================] - 22s 71ms/step - loss: 0.3368 - accuracy: 0.9963 - val_loss: 0.3366 - val_accuracy: 0.9964\n",
            "Epoch 5/50\n",
            "307/307 [==============================] - 22s 71ms/step - loss: 0.3360 - accuracy: 0.9973 - val_loss: 0.3358 - val_accuracy: 0.9971\n",
            "Epoch 6/50\n",
            "307/307 [==============================] - 21s 70ms/step - loss: 0.3355 - accuracy: 0.9978 - val_loss: 0.3354 - val_accuracy: 0.9978\n",
            "Epoch 7/50\n",
            "307/307 [==============================] - 21s 68ms/step - loss: 0.3352 - accuracy: 0.9981 - val_loss: 0.3351 - val_accuracy: 0.9983\n",
            "Epoch 8/50\n",
            "307/307 [==============================] - 21s 68ms/step - loss: 0.3349 - accuracy: 0.9984 - val_loss: 0.3350 - val_accuracy: 0.9982\n",
            "Epoch 9/50\n",
            "307/307 [==============================] - 21s 70ms/step - loss: 0.3348 - accuracy: 0.9985 - val_loss: 0.3350 - val_accuracy: 0.9983\n",
            "Epoch 10/50\n",
            "307/307 [==============================] - 21s 69ms/step - loss: 0.3346 - accuracy: 0.9986 - val_loss: 0.3347 - val_accuracy: 0.9986\n",
            "Epoch 11/50\n",
            "307/307 [==============================] - 21s 70ms/step - loss: 0.3346 - accuracy: 0.9986 - val_loss: 0.3346 - val_accuracy: 0.9987\n",
            "Epoch 12/50\n",
            "307/307 [==============================] - 21s 68ms/step - loss: 0.3344 - accuracy: 0.9987 - val_loss: 0.3344 - val_accuracy: 0.9987\n",
            "Epoch 13/50\n",
            "307/307 [==============================] - 21s 67ms/step - loss: 0.3344 - accuracy: 0.9988 - val_loss: 0.3345 - val_accuracy: 0.9985\n",
            "Epoch 14/50\n",
            "307/307 [==============================] - 22s 70ms/step - loss: 0.3343 - accuracy: 0.9988 - val_loss: 0.3346 - val_accuracy: 0.9984\n",
            "Epoch 15/50\n",
            "307/307 [==============================] - 21s 69ms/step - loss: 0.3343 - accuracy: 0.9989 - val_loss: 0.3345 - val_accuracy: 0.9983\n",
            "Epoch 16/50\n",
            "307/307 [==============================] - 21s 68ms/step - loss: 0.3342 - accuracy: 0.9990 - val_loss: 0.3345 - val_accuracy: 0.9986\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 0.3347 - accuracy: 0.9984\n",
            "[0.3346741795539856, 0.9983532428741455]\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f6ba6350390> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f6ba634b050> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 1s 13ms/step - loss: 0.3347 - accuracy: 0.9984\n",
            "[0.3346741795539856, 0.9983532428741455]\n"
          ]
        }
      ]
    }
  ]
}