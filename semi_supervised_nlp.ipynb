{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTOsXtkhu9Gsb0H8EJc8Ve",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/psriraj17/NLP-3/blob/main/semi_supervised_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDCbnGTE297V",
        "outputId": "e33d1dd6-18f0-479d-beab-052ebb9a9adb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from math import log\n",
        "import numpy as np\n",
        "torch.set_printoptions(precision=10)\n",
        "\n",
        "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Rx8EpgdX_wQZ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dxYt-iXVpq_h"
      },
      "outputs": [],
      "source": [
        "train_file = '/content/drive/MyDrive/train_semi.tsv'\n",
        "val_split = 0.95\n",
        "\n",
        "states = {\n",
        "    '0' :0,\n",
        "    '1' :1,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file):\n",
        "  print(\"Loading data from file {}...\".format(file))\n",
        "  file = open(file, 'r')\n",
        "  data = []\n",
        "  for line in file:\n",
        "      pieces = line.rstrip(\"\\n\").split(\"\\t\")\n",
        "      data.append(pieces)\n",
        "  print(\"Loaded {} sentences\".format(len(data)))\n",
        "  return data\n"
      ],
      "metadata": {
        "id": "gw9_vtz13gfk"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = list(load_data(train_file))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wE5tGBMn38kB",
        "outputId": "6525eac5-7fb4-4ce0-9724-5d99465251d1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from file /content/drive/MyDrive/train_semi.tsv...\n",
            "Loaded 12812 sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Splitting data...\")\n",
        "num_train_samples = int(len(train_data)*(1-val_split))\n",
        "val_data = train_data[num_train_samples:]\n",
        "print(len(val_data),'validation set')\n",
        "train_data = train_data[:num_train_samples]\n",
        "print(len(train_data),\"training set\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ov3gpd86FiO",
        "outputId": "3e7909e6-e23f-4512-9a53-7d473972ebfe"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting data...\n",
            "12172 validation set\n",
            "640 training set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIZJMjlk9iSd",
        "outputId": "aeb1713b-dffd-4628-d8b7-017086355484"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['konsiltan', 'k-on-s-i-l-t-an']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_probabilities_from_counts(counts_dict):\n",
        "    counts_sum = sum(counts_dict.values())\n",
        "    probabilities_dict = {}\n",
        "    for count_id in counts_dict:\n",
        "        count = counts_dict[count_id]\n",
        "        probabilities_dict[count_id] = count / counts_sum\n",
        "    assert round(sum(probabilities_dict.values()), 2) == 1.0, \"All probabilities should sum to 1 but got {}\".format(round(sum(probabilities_dict.values()), 2))\n",
        "    return probabilities_dict"
      ],
      "metadata": {
        "id": "05CPgjIC9nV5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def key_with_max_val(d):\n",
        "    \"\"\"https://stackoverflow.com/questions/268272/getting-key-with-maximum-value-in-dictionary\"\"\"\n",
        "    v = list(d.values())\n",
        "    k = list(d.keys())\n",
        "    return k[v.index(max(v))]"
      ],
      "metadata": {
        "id": "IhEaGKa0-ean"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_initial_state_probabilities(data):\n",
        "    initial_state_counts = states.copy()\n",
        "    # equal probability of starting\n",
        "    for state in initial_state_counts:\n",
        "        initial_state_counts[state] += 1\n",
        "    initial_state_probabilities = compute_probabilities_from_counts(initial_state_counts)\n",
        "    return initial_state_probabilities"
      ],
      "metadata": {
        "id": "ejtR8t-4-lPl"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_transition_state_probabilities(data):\n",
        "    # create a dictionary with two levels, the first being the previous state and the second being the current state\n",
        "    transition_state_counts = {state: states.copy() for state in states}\n",
        "    # since we enumerate over a list that excludes the first item, the enumeration index is one behind\n",
        "    for prev_idx, word in enumerate(data[1:]):\n",
        "        prev_state = data[prev_idx][1]\n",
        "        current_state = word[1]\n",
        "        if prev_state in transition_state_counts and current_state in transition_state_counts[prev_state]:\n",
        "            transition_state_counts[prev_state][current_state] += 1\n",
        "    # setting STOP count to 1 for all states to avoid zeros\n",
        "    for state in transition_state_counts:\n",
        "        transition_state_counts[state]['STOP'] = 1\n",
        "    transition_state_probabilities = {state: {} for state in states}\n",
        "    for prev_state in transition_state_counts:\n",
        "        transition_state_probabilities[prev_state] = compute_probabilities_from_counts(transition_state_counts[prev_state])\n",
        "    return transition_state_probabilities"
      ],
      "metadata": {
        "id": "bnEzkkf0-08k"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_emission_probabilities(data, all_observations):\n",
        "    vocab = {obs: 1 for obs in set(all_observations)}\n",
        "    emission_counts_by_state = {state: vocab for state in states}\n",
        "    for word_state_pair in data:\n",
        "        word, state = word_state_pair\n",
        "        if state in emission_counts_by_state:\n",
        "            # initialize word in state dict if the first occurrence of word X in state Y\n",
        "            if word not in emission_counts_by_state[state]:\n",
        "                emission_counts_by_state[state][word] = 0\n",
        "            emission_counts_by_state[state][word] += 1\n",
        "    emission_probabilities_by_state = {state: {} for state in states}\n",
        "    for state in emission_counts_by_state:\n",
        "        emission_probabilities_by_state[state] = compute_probabilities_from_counts(emission_counts_by_state[state])\n",
        "    return emission_probabilities_by_state"
      ],
      "metadata": {
        "id": "OQ6Lyoet_C-g"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(data, vocab):\n",
        "        print(\"Fitting model to provided dataset...\")\n",
        "        initial_state_probabilities = generate_initial_state_probabilities(data)\n",
        "        transition_probabilities = generate_transition_state_probabilities(data)\n",
        "        emission_probabilities = generate_emission_probabilities(data, vocab)\n",
        "        print(\"Model ready.\")\n",
        "        return initial_state_probabilities, transition_probabilities, emission_probabilities"
      ],
      "metadata": {
        "id": "Gqb77Vv6_SvG"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_sequence = [pair[0] for pair in val_data]\n",
        "val_labels = [pair[1] for pair in val_data]\n",
        "initial, transition, emission  = fit(train_data, val_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rudivogO_YO5",
        "outputId": "15a14212-9fea-4072-8cb7-ebdfb9d98f54"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model to provided dataset...\n",
            "Model ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_forward_prob(observations):\n",
        "    forward_probabilities = {}\n",
        "    for idx, observation in enumerate(observations):\n",
        "        for state in initial:\n",
        "            if idx == 0:\n",
        "                probability = initial[state]*emission[state][observation] if observation in emission[state] else 0\n",
        "                forward_probabilities[state] = torch.DoubleTensor([probability])\n",
        "            else:\n",
        "                probability = 0\n",
        "                for prev_state in transition:\n",
        "                    probability += forward_probabilities[prev_state][idx-1]*transition[prev_state][state]\n",
        "                probability *= emission[state][observation]\n",
        "                forward_probabilities[state] = torch.cat((forward_probabilities[state], torch.DoubleTensor([probability])))\n",
        "    return forward_probabilities"
      ],
      "metadata": {
        "id": "tREcVHI3_orQ"
      },
      "execution_count": 46,
      "outputs": []
    }
  ]
}