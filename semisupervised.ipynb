{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMIE7wytOkpr2RVlNWJDuD6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreihMurray/NLP-3/blob/Semi_Murray/semisupervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zwkkSetusdVb"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import load_model\n",
        "import joblib\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from numpy import concatenate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjngr6X6sk7r",
        "outputId": "c92c8e25-df24-41f9-e4be-de51c491a2af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "LOrbZInp2lY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file_to_sents():\n",
        "    all_data = []\n",
        "    with open(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/train.tsv\", encoding=\"utf-8\") as file:\n",
        "        f = csv.reader(file, delimiter=\"\\t\")\n",
        "        for line in tqdm(f, desc=\"Reading data...\"):\n",
        "            word = line[0]\n",
        "            graphemes = line[1].split('-')\n",
        "\n",
        "            cur_word = []\n",
        "\n",
        "            for i in range(0, len(graphemes)):\n",
        "                for j in range(0, len(graphemes[i])):\n",
        "                    if j == 0:\n",
        "                        cur_word.append((graphemes[i][j], 'B'))\n",
        "                    else:\n",
        "                        cur_word.append((graphemes[i][j], 'I'))\n",
        "\n",
        "            all_data.append(cur_word)\n",
        "\n",
        "    return all_data"
      ],
      "metadata": {
        "id": "pEpjh6qgsoYf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "9zD5BnvUaj3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data):\n",
        "    split_x = []\n",
        "    split_y = []\n",
        "    \n",
        "    for word in data:\n",
        "        cur_x = []\n",
        "        cur_y = []\n",
        "        for letter in word:\n",
        "            cur_x.append(letter[0])\n",
        "            cur_y.append(letter[1])\n",
        "\n",
        "        split_x.append(cur_x)\n",
        "        split_y.append(cur_y)\n",
        "\n",
        "    return split_x, split_y"
      ],
      "metadata": {
        "id": "CqSPyByEtTj9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "original"
      ],
      "metadata": {
        "id": "CRBqIXaxago5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_all_y(y):\n",
        "    all_y = []\n",
        "\n",
        "    for entry in y:\n",
        "        for letter in entry:\n",
        "            all_y.append(letter)\n",
        "\n",
        "    return all_y"
      ],
      "metadata": {
        "id": "NjrEIguxR2u2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "original"
      ],
      "metadata": {
        "id": "QQGEbxAwaf4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_out(x, y):\n",
        "    fixed_y = []\n",
        "\n",
        "    track_y = 0\n",
        "\n",
        "    for j in range(0, len(x)):\n",
        "        cur_word = []\n",
        "        for i in range(0, len(x[j])):\n",
        "            cur_word.append(y[track_y])\n",
        "            track_y += 1\n",
        "        fixed_y.append(cur_word)\n",
        "\n",
        "    return fixed_y\n",
        "        "
      ],
      "metadata": {
        "id": "lfvbBNrTStwR"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_acc(preds, y_test):\n",
        "    total_right = 0\n",
        "\n",
        "    total_size = 0\n",
        "\n",
        "    for i in range(0, len(preds)):\n",
        "        for j in range(0, len(preds[i])):\n",
        "          if preds[i][j] == y_test[i][j]:\n",
        "              total_right += 1\n",
        "          total_size += 1\n",
        "\n",
        "    accuracy = 100 * (total_right/total_size)\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "UlPOHdTtNt0Z"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_rec(preds, y_test):\n",
        "    true_pos = 0\n",
        "    false_neg = 0\n",
        "\n",
        "    for i in range(0, len(preds)):\n",
        "        for j in range(0, len(preds[i])):\n",
        "            if preds[i][j] == 'I' and y_test[i][j] == 'I':\n",
        "                true_pos += 1\n",
        "            if preds[i][j] == 'B' and y_test[i][j] == 'I':\n",
        "                false_neg += 1\n",
        "\n",
        "    if true_pos + false_neg == 0:\n",
        "        return 0\n",
        "        \n",
        "    recall = 100 * (true_pos / (true_pos + false_neg))\n",
        "\n",
        "    return recall"
      ],
      "metadata": {
        "id": "9Si092wuN0r7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_prec(preds, y_test):  \n",
        "    true_pos = 0\n",
        "    false_pos = 0\n",
        "\n",
        "    for i in range(0, len(preds)):\n",
        "        for j in range(0, len(preds[i])):\n",
        "            if preds[i][j] == 'I' and y_test[i][j] == 'I':\n",
        "                true_pos += 1\n",
        "            if preds[i][j] == 'I' and y_test[i][j] == 'B':\n",
        "                false_pos += 1\n",
        "\n",
        "    if (true_pos + false_pos) == 0:\n",
        "        return 0.01\n",
        "\n",
        "    precision = 100 * (true_pos / (true_pos + false_pos))\n",
        "\n",
        "    return precision"
      ],
      "metadata": {
        "id": "TWe2rpGYNxup"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_eval(preds, y_clean):\n",
        "    acc = calc_acc(preds, y_clean)\n",
        "\n",
        "    print(\"Custom calculated Accuracy: \", acc)\n",
        "\n",
        "    prec = calc_prec(preds, y_clean)\n",
        "\n",
        "    print(\"Precision: \", prec)\n",
        "\n",
        "    recall = calc_rec(preds, y_clean)\n",
        "\n",
        "    print(\"Recall: \", recall)\n",
        "\n",
        "    fscore = (2 * (prec * recall)) / (prec + recall)\n",
        "\n",
        "    print(\"Fscore: \", fscore)"
      ],
      "metadata": {
        "id": "ISMUcoOzNnOR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://machinelearningmastery.com/semi-supervised-learning-with-label-propagation/"
      ],
      "metadata": {
        "id": "tYgh3vOOaeHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def semi_supervised():\n",
        "    data = read_file_to_sents()\n",
        "\n",
        "    x, y = split_data(data)\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.5, random_state = 50)\n",
        "    clean_y_test = y_test\n",
        "\n",
        "    x_lab = combine_all_y(x_train[:650])\n",
        "    y_lab = combine_all_y(y_train[:650])\n",
        "    x_train = combine_all_y(x_train[650:])\n",
        "\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    le.fit(y_lab)\n",
        "    y_hold = le.transform(y_lab)\n",
        "\n",
        "    x_train_mixed = concatenate((x_lab, x_train))\n",
        "    fle = LabelEncoder()\n",
        "    fle.fit(x_train_mixed)\n",
        "    x_train_mixed = fle.transform(x_train_mixed)\n",
        "    x_train_mixed = x_train_mixed.reshape(-1, 1)\n",
        "\n",
        "    nolabel = [-1 for _ in range(len(y_hold), len(x_train_mixed))]\n",
        "\n",
        "    y_train_mixed = concatenate((y_hold, nolabel))\n",
        "\n",
        "    model = LabelPropagation(max_iter=1000, tol=0.05, n_jobs = -1, kernel='rbf', gamma=30)\n",
        "\n",
        "    model.fit(x_train_mixed, y_train_mixed)\n",
        "\n",
        "    x_test = combine_all_y(x_test)\n",
        "    x_test = fle.transform(x_test)\n",
        "    x_test = x_test.reshape(-1, 1)\n",
        "\n",
        "    y_hat = model.predict(x_test)\n",
        "    y_test = combine_all_y(y_test)\n",
        "    y_test = le.transform(y_test)\n",
        "    y_test = y_test.reshape(-1, 1)\n",
        "\n",
        "    score = accuracy_score(y_test, y_hat)\n",
        "    print(score*100)\n",
        "\n",
        "    clean_preds = le.inverse_transform(y_hat)\n",
        "    clean_preds = split_out(clean_y_test, clean_preds)\n",
        "\n",
        "    custom_eval(clean_preds, clean_y_test)"
      ],
      "metadata": {
        "id": "-NtZSkDetvsB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "HQyTtVkr3SzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "semi_supervised()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn5J86L8uH9u",
        "outputId": "f7c8cb9e-99bc-4515-99b1-0baa79e5134d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading data...: 12812it [00:00, 206585.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96.95180557462584\n",
            "Custom calculated Accuracy:  96.95180557462584\n",
            "Precision:  74.34885556432518\n",
            "Recall:  99.1578947368421\n",
            "Fscore:  84.97970230040596\n"
          ]
        }
      ]
    }
  ]
}