{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNYw5yW4eJhjj08IwBFWgzo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreihMurray/NLP-3/blob/Semi_Murray/semisupervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwkkSetusdVb"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Reshape\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import load_model\n",
        "import joblib\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "import nltk\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import json\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from numpy import concatenate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjngr6X6sk7r",
        "outputId": "702fe7c3-cdce-4b40-a254-28a772087d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "LOrbZInp2lY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file_to_sents():\n",
        "    all_data = []\n",
        "    with open(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/train.tsv\", encoding=\"utf-8\") as file:\n",
        "        f = csv.reader(file, delimiter=\"\\t\")\n",
        "        for line in tqdm(f, desc=\"Reading data...\"):\n",
        "            word = line[0]\n",
        "            graphemes = line[1].split('-')\n",
        "\n",
        "            cur_word = []\n",
        "\n",
        "            for i in range(0, len(graphemes)):\n",
        "                for j in range(0, len(graphemes[i])):\n",
        "                    if j == 0:\n",
        "                        cur_word.append((graphemes[i][j], 'B'))\n",
        "                    else:\n",
        "                        cur_word.append((graphemes[i][j], 'I'))\n",
        "\n",
        "            all_data.append(cur_word)\n",
        "\n",
        "    return all_data"
      ],
      "metadata": {
        "id": "pEpjh6qgsoYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "9zD5BnvUaj3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data):\n",
        "    split_x = []\n",
        "    split_y = []\n",
        "    \n",
        "    for word in data:\n",
        "        cur_x = []\n",
        "        cur_y = []\n",
        "        for letter in word:\n",
        "            cur_x.append(letter[0])\n",
        "            cur_y.append(letter[1])\n",
        "\n",
        "        split_x.append(cur_x)\n",
        "        split_y.append(cur_y)\n",
        "\n",
        "    return split_x, split_y"
      ],
      "metadata": {
        "id": "CqSPyByEtTj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "original"
      ],
      "metadata": {
        "id": "CRBqIXaxago5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_all_y(y):\n",
        "    all_y = []\n",
        "\n",
        "    for entry in y:\n",
        "        for letter in entry:\n",
        "            all_y.append(letter)\n",
        "\n",
        "    return all_y"
      ],
      "metadata": {
        "id": "NjrEIguxR2u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "original"
      ],
      "metadata": {
        "id": "QQGEbxAwaf4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_out(x, y):\n",
        "    fixed_y = []\n",
        "\n",
        "    for j in range(0, len(x)):\n",
        "        cur_word = []\n",
        "        for i in range(0, len(x[j])):\n",
        "            cur_word.append(y[i])\n",
        "        fixed_y.append(cur_word)\n",
        "\n",
        "    return fixed_y\n",
        "        "
      ],
      "metadata": {
        "id": "lfvbBNrTStwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on code from https://machinelearningmastery.com/semi-supervised-learning-with-label-propagation/"
      ],
      "metadata": {
        "id": "tYgh3vOOaeHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def semi_supervised():\n",
        "    data = read_file_to_sents()\n",
        "\n",
        "    x, y = split_data(data)\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.5, random_state = 50)\n",
        "\n",
        "    x_lab = combine_all_y(x_train[:650])\n",
        "    y_lab = combine_all_y(y_train[:650])\n",
        "    x_train = combine_all_y(x_train[650:])\n",
        "\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    le.fit(y_lab)\n",
        "    y_hold = le.transform(y_lab)\n",
        "\n",
        "    x_train_mixed = concatenate((x_lab, x_train))\n",
        "    fle = LabelEncoder()\n",
        "    fle.fit(x_train_mixed)\n",
        "    x_train_mixed = fle.transform(x_train_mixed)\n",
        "    x_train_mixed = x_train_mixed.reshape(-1, 1)\n",
        "\n",
        "    nolabel = [-1 for _ in range(len(y_hold), len(x_train_mixed))]\n",
        "\n",
        "    y_train_mixed = concatenate((y_hold, nolabel))\n",
        "\n",
        "    print(len(x_train_mixed))\n",
        "    print(len(y_train_mixed))\n",
        "\n",
        "    model = LabelPropagation()\n",
        "\n",
        "    model.fit(x_train_mixed, y_train_mixed)\n",
        "\n",
        "    x_test = combine_all_y(x_test)\n",
        "    x_test = fle.transform(x_test)\n",
        "    x_test = x_test.reshape(-1, 1)\n",
        "\n",
        "    y_hat = model.predict(x_test)\n",
        "    y_test = combine_all_y(y_test)\n",
        "    y_test = le.transform(y_test)\n",
        "    y_test = y_test.reshape(-1, 1)\n",
        "\n",
        "\n",
        "    score = accuracy_score(y_test, y_hat)\n",
        "\n",
        "    print(score*100)"
      ],
      "metadata": {
        "id": "-NtZSkDetvsB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original"
      ],
      "metadata": {
        "id": "HQyTtVkr3SzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "semi_supervised()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn5J86L8uH9u",
        "outputId": "058dc935-b04e-4eb0-8093-b680a03cc460"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading data...: 12812it [00:00, 203356.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43606\n",
            "43606\n",
            "96.95180557462584\n"
          ]
        }
      ]
    }
  ]
}