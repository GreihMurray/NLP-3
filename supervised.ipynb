{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuFq00zgorhw2jRr0V5RMj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreihMurray/NLP-3/blob/Super_Murray/supervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "zwkkSetusdVb"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Reshape\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import load_model\n",
        "import joblib\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "import nltk\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjngr6X6sk7r",
        "outputId": "336f5799-0d6a-4b0b-cf81-cbd0d32137fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file_to_sents():\n",
        "    all_data = []\n",
        "    with open(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/train.tsv\", encoding=\"utf-8\") as file:\n",
        "        f = csv.reader(file, delimiter=\"\\t\")\n",
        "        for line in tqdm(f, desc=\"Reading data...\"):\n",
        "            word = line[0]\n",
        "            graphemes = line[1].split('-')\n",
        "\n",
        "            cur_word = []\n",
        "\n",
        "            for i in range(0, len(graphemes)):\n",
        "                for j in range(0, len(graphemes[i])):\n",
        "                    if j == 0:\n",
        "                        cur_word.append((graphemes[i][j], 'B'))\n",
        "                    else:\n",
        "                        cur_word.append((graphemes[i][j], 'I'))\n",
        "\n",
        "            all_data.append(cur_word)\n",
        "\n",
        "    return all_data"
      ],
      "metadata": {
        "id": "pEpjh6qgsoYf"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad(data):\n",
        "  vocab = list(set([w for sent in data for (w,t) in sent]))\n",
        "  vocab.append('<PAD>')\n",
        "  tags = list(set([t for sent in data for (w,t) in sent]))\n",
        "  tags.append('<PAD>')\n",
        "\n",
        "  return vocab, tags"
      ],
      "metadata": {
        "id": "SyCX8WWu4Wis"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(vocab, tags, data, load=False):\n",
        "  max_len = max([len(i) for i in data])\n",
        "\n",
        "  word2index = {}\n",
        "  tag2index = {}\n",
        "\n",
        "  if load is False:\n",
        "      word2index = {w: i for i, w in enumerate(vocab)}\n",
        "      tag2index = {t: i for i, t in enumerate(tags)}\n",
        "  else:\n",
        "      with open(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/word2index.json\") as infile:\n",
        "          word2index = json.load(infile)  \n",
        "\n",
        "      with open(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/tag2index.json\") as outfile:\n",
        "          tag2index = json.load(outfile)\n",
        "\n",
        "  onehot = [[word2index[w[0]] for w in s] for s in data]\n",
        "  X = pad_sequences(maxlen=max_len, sequences=onehot, padding=\"post\", value=len(vocab)-1)  \n",
        "\n",
        "  onehot_y = [[tag2index[w[1]] for w in s] for s in data]\n",
        "  y = pad_sequences(maxlen=max_len, sequences=onehot_y, padding=\"post\", value=tag2index[\"<PAD>\"])\n",
        "  y = to_categorical(y, num_classes=len(tags))\n",
        "\n",
        "  # Used for saving word2index and tag2index in order to encode additional data in the same manner\n",
        "  # Currently commented out due to issues with loading model\n",
        "  with open(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/word2index.json\", \"w\") as outfile:\n",
        "    json.dump(word2index, outfile)\n",
        "\n",
        "  with open(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/tag2index.json\", \"w\") as outfile:\n",
        "    json.dump(tag2index, outfile)\n",
        "\n",
        "  return X, y, max_len"
      ],
      "metadata": {
        "id": "nzxivxza4ZKR"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seq_model(data):\n",
        "  #Original\n",
        "    vocab, tags = pad(data)\n",
        "\n",
        "    x, y, max_len = encode(vocab, tags, data)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
        "  \n",
        "  \n",
        "  # Dr. Scannell\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(vocab), output_dim=50, input_length=max_len))\n",
        "    model.add(Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.05)))\n",
        "    model.add(TimeDistributed(Dense(len(tags), activation=\"softmax\")))\n",
        "    model.compile(optimizer=\"adam\", loss=\"poisson\", metrics=[\"accuracy\"])\n",
        "  # From https://towardsdatascience.com/hyperparameter-tuning-with-kerastuner-and-tensorflow-c4a4d690b31a\n",
        "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)\n",
        "\n",
        "    print(\"[INFO] training network...\")\n",
        "    sgd = SGD(0.05)\n",
        "    history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_split=0.15, verbose=1, callbacks=stop_early)\n",
        "\n",
        "    return model, X_test, y_test"
      ],
      "metadata": {
        "id": "FVR17k8e4bxB"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_precision(preds, y_test):\n",
        "    true_pos = 0\n",
        "    false_pos = 0\n",
        "\n",
        "    for i in range(0, len(preds)):\n",
        "        if str(preds[i]) == 'B' and str(y_test[i]) == 'B':\n",
        "            true_pos += 1\n",
        "        if str(preds[i]) == 'B' and str(y_test[i]) == 'I':\n",
        "            false_pos += 1\n",
        "\n",
        "    if (true_pos + false_pos) == 0:\n",
        "        return 0.01\n",
        "\n",
        "    precision = 100 * (true_pos / (true_pos + false_pos))\n",
        "\n",
        "    return precision"
      ],
      "metadata": {
        "id": "Y9m8uO1d-_KH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_recall(preds, y_test):\n",
        "    true_pos = 0\n",
        "    false_neg = 0\n",
        "\n",
        "    for i in range(0, len(preds)):\n",
        "        if str(preds[i]) == 'B' and str(y_test[i]) == 'B':\n",
        "            true_pos += 1\n",
        "        if str(preds[i]) == 'I' and str(y_test[i]) == 'B':\n",
        "            false_neg += 1\n",
        "\n",
        "    if true_pos + false_neg == 0:\n",
        "        return 0\n",
        "        \n",
        "    recall = 100 * (true_pos / (true_pos + false_neg))\n",
        "\n",
        "    return recall"
      ],
      "metadata": {
        "id": "KYP5sEdp_eg7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, x_test, y_test):\n",
        "    eval = model.evaluate(x_test, y_test)\n",
        "    print(eval)"
      ],
      "metadata": {
        "id": "k_MUYsLr40jx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def supervised():\n",
        "    data = read_file_to_sents()\n",
        "\n",
        "    model, x_test, y_test = seq_model(data)\n",
        "\n",
        "    eval_model(model, x_test, y_test) # Eval sequential model\n",
        "\n",
        "    model.save('/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/adamPoisson32_seq_model')\n",
        "\n",
        "    new_model = load_model('/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/adamPoisson32_seq_model')\n",
        "\n",
        "    eval_model(new_model, x_test, y_test)"
      ],
      "metadata": {
        "id": "-NtZSkDetvsB"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_eval_model():\n",
        "    data = read_file_to_sents()\n",
        "\n",
        "    vocab, tags = pad(data)\n",
        "\n",
        "    x, y, max_len = encode(vocab, tags, data, load=True)\n",
        "\n",
        "    new_model = load_model('/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/adamPoisson32_seq_model')\n",
        "\n",
        "    eval_model(new_model, x, y)"
      ],
      "metadata": {
        "id": "hvLR537CzpQg"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def undo_encode(x, y):\n",
        "    all_data = []\n",
        "    all_words = []\n",
        "    all_tags = []\n",
        "\n",
        "    word2index = {}\n",
        "    tag2index = {}\n",
        "\n",
        "    with open(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/word2index.json\") as infile:\n",
        "          word2index = json.load(infile)  \n",
        "\n",
        "    with open(\"/content/gdrive/MyDrive/Colab_Notebooks/NLP/kreole/tag2index.json\") as outfile:\n",
        "          tag2index = json.load(outfile)\n",
        "\n",
        "    for word in x:\n",
        "        cur_word = []\n",
        "        for letter in word:\n",
        "            if letter == 51:\n",
        "                break\n",
        "            true_letter = list(word2index.keys())[list(word2index.values()).index(letter)]\n",
        "            cur_word.append(true_letter)\n",
        "\n",
        "        all_words.append(''.join(cur_word))\n",
        "\n",
        "    for tags in y:\n",
        "        cur_tags = []\n",
        "        for tag in tags:\n",
        "            if tag[0] == 1:\n",
        "                cur_tags.append('I')\n",
        "            elif tag[1] == 1:\n",
        "                cur_tags.append('B')\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "        all_tags.append(''.join(cur_tags))\n",
        "\n",
        "    for i in range(0, len(all_words)):\n",
        "        all_data.append((all_words[i], all_tags[i]))\n",
        "\n",
        "    return all_data"
      ],
      "metadata": {
        "id": "JvMIudG_2Zv-"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_graphemes(data):\n",
        "    graph_data = []\n",
        "\n",
        "    for word_pair in data:\n",
        "        word = word_pair[0]\n",
        "        grap = word_pair[1]\n",
        "\n",
        "        cur_word = []\n",
        "\n",
        "        for i in range(0, len(word)):\n",
        "            if i == (len(word) - 1):\n",
        "                cur_word.append(word[i])\n",
        "\n",
        "            else:\n",
        "                if grap[i+1] == 'I':\n",
        "                    cur_word.append(word[i])\n",
        "                else:\n",
        "                    cur_word.append(word[i] + '-')\n",
        "\n",
        "        graph_data.append((word, ''.join(cur_word)))\n",
        "\n",
        "    return graph_data\n"
      ],
      "metadata": {
        "id": "Q67tirhiFCSp"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_and_eval_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJslV8Ryz3R2",
        "outputId": "7486fad7-53a6-4697-e4e5-bce3018f3735"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading data...: 12812it [00:00, 164230.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "<class 'dict'>\n",
            "401/401 [==============================] - 6s 13ms/step - loss: 0.3799 - accuracy: 0.9794\n",
            "[0.37994199991226196, 0.9793943166732788]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "supervised()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn5J86L8uH9u",
        "outputId": "bdaada05-e536-4748-9d3f-b9a33d1d4b29"
      },
      "execution_count": 210,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reading data...: 12812it [00:00, 149777.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training network...\n",
            "Epoch 1/50\n",
            "307/307 [==============================] - 28s 74ms/step - loss: 0.3803 - accuracy: 0.9574 - val_loss: 0.3404 - val_accuracy: 0.9921\n",
            "Epoch 2/50\n",
            "307/307 [==============================] - 25s 81ms/step - loss: 0.3380 - accuracy: 0.9958 - val_loss: 0.3364 - val_accuracy: 0.9972\n",
            "Epoch 3/50\n",
            "307/307 [==============================] - 23s 74ms/step - loss: 0.3359 - accuracy: 0.9978 - val_loss: 0.3347 - val_accuracy: 0.9989\n",
            "Epoch 4/50\n",
            "307/307 [==============================] - 24s 77ms/step - loss: 0.3347 - accuracy: 0.9992 - val_loss: 0.3341 - val_accuracy: 0.9995\n",
            "Epoch 5/50\n",
            "307/307 [==============================] - 24s 77ms/step - loss: 0.3344 - accuracy: 0.9992 - val_loss: 0.3339 - val_accuracy: 0.9995\n",
            "Epoch 6/50\n",
            "307/307 [==============================] - 24s 78ms/step - loss: 0.3341 - accuracy: 0.9994 - val_loss: 0.3337 - val_accuracy: 0.9996\n",
            "Epoch 7/50\n",
            "307/307 [==============================] - 24s 79ms/step - loss: 0.3339 - accuracy: 0.9995 - val_loss: 0.3336 - val_accuracy: 0.9998\n",
            "Epoch 8/50\n",
            "307/307 [==============================] - 23s 73ms/step - loss: 0.3338 - accuracy: 0.9996 - val_loss: 0.3336 - val_accuracy: 0.9998\n",
            "Epoch 9/50\n",
            "307/307 [==============================] - 24s 77ms/step - loss: 0.3337 - accuracy: 0.9997 - val_loss: 0.3335 - val_accuracy: 0.9999\n",
            "Epoch 10/50\n",
            "307/307 [==============================] - 23s 76ms/step - loss: 0.3337 - accuracy: 0.9997 - val_loss: 0.3336 - val_accuracy: 0.9997\n",
            "Epoch 11/50\n",
            "307/307 [==============================] - 25s 82ms/step - loss: 0.3336 - accuracy: 0.9998 - val_loss: 0.3335 - val_accuracy: 0.9999\n",
            "Epoch 12/50\n",
            "307/307 [==============================] - 22s 71ms/step - loss: 0.3336 - accuracy: 0.9998 - val_loss: 0.3335 - val_accuracy: 0.9999\n",
            "Epoch 13/50\n",
            "307/307 [==============================] - 24s 77ms/step - loss: 0.3335 - accuracy: 0.9998 - val_loss: 0.3335 - val_accuracy: 0.9999\n",
            "Epoch 14/50\n",
            "307/307 [==============================] - 24s 77ms/step - loss: 0.3335 - accuracy: 0.9999 - val_loss: 0.3334 - val_accuracy: 0.9999\n",
            "Epoch 15/50\n",
            "307/307 [==============================] - 23s 75ms/step - loss: 0.3335 - accuracy: 0.9998 - val_loss: 0.3335 - val_accuracy: 0.9999\n",
            "Epoch 16/50\n",
            "307/307 [==============================] - 23s 74ms/step - loss: 0.3335 - accuracy: 0.9998 - val_loss: 0.3334 - val_accuracy: 0.9999\n",
            "Epoch 17/50\n",
            "307/307 [==============================] - 23s 76ms/step - loss: 0.3335 - accuracy: 0.9999 - val_loss: 0.3335 - val_accuracy: 0.9997\n",
            "41/41 [==============================] - 1s 14ms/step - loss: 0.3338 - accuracy: 0.9997\n",
            "[0.3338024318218231, 0.9996533393859863]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f6ba5329d50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f6ba5322a90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 1s 12ms/step - loss: 0.3338 - accuracy: 0.9997\n",
            "[0.3338024318218231, 0.9996533393859863]\n"
          ]
        }
      ]
    }
  ]
}